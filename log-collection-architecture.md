# ğŸš€ ì„œë²„ ë¡œê·¸ ìˆ˜ì§‘ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

## ğŸ“‹ ì‹œìŠ¤í…œ ê°œìš”

ìš´ì˜/í…ŒìŠ¤íŠ¸ í™˜ê²½ì—ì„œ ëŒ€ê·œëª¨ ì„œë²„ ë¡œê·¸ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ìˆ˜ì§‘, ì²˜ë¦¬, ì €ì¥, ë¶„ì„í•  ìˆ˜ ìˆëŠ” í†µí•© ë¡œê·¸ ê´€ë¦¬ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

### ğŸ¯ í•µì‹¬ ëª©í‘œ
- **ì‹¤ì‹œê°„ ë¡œê·¸ ìˆ˜ì§‘**: ë‹¤ì–‘í•œ ì„œë²„ì—ì„œ ë°œìƒí•˜ëŠ” ë¡œê·¸ì˜ ì‹¤ì‹œê°„ ìˆ˜ì§‘
- **ì¤‘ì•™í™” ê´€ë¦¬**: ë¶„ì‚°ëœ ì„œë²„ ë¡œê·¸ì˜ ì¤‘ì•™ ì§‘ì¤‘ ê´€ë¦¬
- **íš¨ìœ¨ì  ì €ì¥**: ëŒ€ìš©ëŸ‰ ë¡œê·¸ ë°ì´í„°ì˜ ë¹„ìš© íš¨ìœ¨ì  ì €ì¥
- **ë¹ ë¥¸ ê²€ìƒ‰**: ë¡œê·¸ ë°ì´í„°ì˜ ì‹¤ì‹œê°„ ê²€ìƒ‰ ë° ë¶„ì„
- **ëª¨ë‹ˆí„°ë§**: ì´ìƒ ìƒí™© ê°ì§€ ë° ì‹¤ì‹œê°„ ì•Œë¦¼

## ğŸ—ï¸ ì•„í‚¤í…ì²˜ ì„¤ê³„

### 1. ìˆ˜ì§‘ ê³„ì¸µ (Collection Layer)
```
[Application Servers]
        â†“
[Log Agents] â†’ [Message Queue] â†’ [Processing Pipeline]
```

**ì£¼ìš” ì»´í¬ë„ŒíŠ¸:**
- **Filebeat/Fluentd**: ë¡œê·¸ íŒŒì¼ ìˆ˜ì§‘ ì—ì´ì „íŠ¸
- **Vector**: ê³ ì„±ëŠ¥ ë¡œê·¸ ë¼ìš°í„° ë° ë³€í™˜ê¸°
- **Kafka**: ëŒ€ìš©ëŸ‰ ë©”ì‹œì§€ í (ë²„í¼ë§, ë‚´ê²°í•¨ì„±)

### 2. ì²˜ë¦¬ ê³„ì¸µ (Processing Layer)
```
[Raw Logs] â†’ [Parse/Filter] â†’ [Enrich] â†’ [Route]
```

**ì²˜ë¦¬ ê¸°ëŠ¥:**
- ë¡œê·¸ íŒŒì‹± ë° êµ¬ì¡°í™”
- í•„í„°ë§ ë° ë…¸ì´ì¦ˆ ì œê±°
- ë©”íƒ€ë°ì´í„° ì¶”ê°€ (timestamp, source, environment)
- ë¡œê·¸ ë ˆë²¨ë³„ ë¼ìš°íŒ…

### 3. ì €ì¥ ê³„ì¸µ (Storage Layer)
```
Hot Data (Elasticsearch) â† Real-time Search
Warm Data (S3/GCS) â† Medium-term Storage  
Cold Data (Glacier) â† Long-term Archive
```

### 4. ë¶„ì„ ê³„ì¸µ (Analytics Layer)
```
[Kibana/Grafana] â† Visualization
[Alertmanager] â† Monitoring
[Custom APIs] â† Application Integration
```

## ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ ì„ íƒ

### Option 1: ELK Stack (Elasticsearch, Logstash, Kibana)
**ì¥ì :**
- ì„±ìˆ™í•œ ìƒíƒœê³„
- ê°•ë ¥í•œ ì „ë¬¸ ê²€ìƒ‰
- í’ë¶€í•œ ì‹œê°í™”

**ë‹¨ì :**
- ë†’ì€ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
- ë³µì¡í•œ ìš´ì˜

### Option 2: EFK Stack (Elasticsearch, Fluentd, Kibana)
**ì¥ì :**
- ë” ê°€ë²¼ìš´ ìˆ˜ì§‘ ì—ì´ì „íŠ¸
- ìœ ì—°í•œ í”ŒëŸ¬ê·¸ì¸ ì‹œìŠ¤í…œ
- Ruby ê¸°ë°˜ í™•ì¥ì„±

### Option 3: Grafana Loki Stack
**ì¥ì :**
- ë‚®ì€ ìš´ì˜ ë¹„ìš©
- í”„ë¡œë©”í…Œìš°ìŠ¤ì™€ ìì—°ìŠ¤ëŸ¬ìš´ í†µí•©
- ë ˆì´ë¸” ê¸°ë°˜ ì¸ë±ì‹±

### Option 4: í´ë¼ìš°ë“œ ê´€ë¦¬í˜• ì„œë¹„ìŠ¤
**AWS:** CloudWatch Logs, Kinesis Data Firehose
**GCP:** Cloud Logging, Pub/Sub
**Azure:** Azure Monitor, Event Hubs

## ğŸ”§ êµ¬í˜„ ì˜ˆì‹œ

### Docker Compose ê¸°ë°˜ ELK ìŠ¤íƒ
```yaml
version: '3.8'

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data

  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    ports:
      - "5044:5044"
      - "9600:9600"
    volumes:
      - ./logstash/config:/usr/share/logstash/pipeline
    environment:
      - "LS_JAVA_OPTS=-Xmx512m -Xms512m"
    depends_on:
      - elasticsearch

  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      - elasticsearch

  filebeat:
    image: docker.elastic.co/beats/filebeat:8.11.0
    user: root
    volumes:
      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/log:/var/log:ro
    depends_on:
      - logstash

volumes:
  elasticsearch_data:
```

### Filebeat ì„¤ì •
```yaml
# filebeat.yml
filebeat.inputs:
- type: log
  enabled: true
  paths:
    - /var/log/app/*.log
  fields:
    logtype: application
    environment: production
  fields_under_root: true
  multiline.pattern: '^\d{4}-\d{2}-\d{2}'
  multiline.negate: true
  multiline.match: after

- type: docker
  containers.ids: "*"
  processors:
  - add_docker_metadata: ~

output.logstash:
  hosts: ["logstash:5044"]

processors:
- add_host_metadata:
    when.not.contains.tags: forwarded
```

### Logstash íŒŒì´í”„ë¼ì¸
```ruby
# logstash/config/pipeline.conf
input {
  beats {
    port => 5044
  }
}

filter {
  # JSON ë¡œê·¸ íŒŒì‹±
  if [fields][logtype] == "application" {
    json {
      source => "message"
    }
  }
  
  # ë‚ ì§œ íŒŒì‹±
  date {
    match => [ "timestamp", "yyyy-MM-dd HH:mm:ss" ]
  }
  
  # ë¡œê·¸ ë ˆë²¨ ì •ê·œí™”
  mutate {
    uppercase => [ "level" ]
  }
  
  # ë¶ˆí•„ìš”í•œ í•„ë“œ ì œê±°
  mutate {
    remove_field => [ "agent", "ecs", "host" ]
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "logs-%{[fields][environment]}-%{+YYYY.MM.dd}"
    template_name => "logs"
    template_pattern => "logs-*"
    template => {
      "index_patterns" => ["logs-*"],
      "settings" => {
        "number_of_shards" => 1,
        "number_of_replicas" => 0
      }
    }
  }
  
  stdout {
    codec => rubydebug
  }
}
```